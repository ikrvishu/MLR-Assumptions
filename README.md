These are the assumptions of multiple linear regression and each code is in the file

Linearity: There is a linear relationship between the dependent variable and each of the independent variables. This means that the change in the dependent variable is proportional to the change in the independent variable, holding all other independent variables constant. You can check for linearity by creating scatterplots of the dependent variable versus each independent variable.

Homoscedasticity: The variance of the errors is constant for all values of the independent variables. This means that the spread of the data points around the regression line is consistent. You can check for homoscedasticity by creating a scatterplot of the residuals (the differences between the actual values of the dependent variable and the predicted values) versus the predicted values.

Independence of errors: The errors are independent of each other. This means that the error for one observation does not influence the error for any other observation. You can check for independence of errors by looking for patterns in the residuals, such as autocorrelation or serial correlation.

Normality of errors: The errors are normally distributed. This means that the errors are bell-shaped and symmetrical. You can check for normality of errors by creating a histogram of the residuals.

No multicollinearity: The independent variables are not highly correlated with each other. Multicollinearity occurs when two or more independent variables are so highly correlated that it is difficult to separate their individual effects on the dependent variable. You can check for multicollinearity by calculating the variance inflation factor (VIF) for each independent variable.
